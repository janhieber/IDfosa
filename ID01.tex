\begin{multicols}{2}

\subsection*{Binärlogarithmus}
\[
    \log_2{x} = \frac{\log{x}}{\log{2}}
\]

\subsection*{Entscheidungsgehalt}
\[
    H_0 = \log_2{K} \mbox{ mit } K = \text{Anzahl Symbole}
\]

\subsection*{Informationsgehalt}
\begin{minipage}{\columnwidth}
\[
    I(a_k) = -\log_2{P(a_k)} \mbox{ [Bit]}
\]
\begin{itemize}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{0pt}
	\item Je kleiner $P(a_k)$, desto größer $I$.
	\item Wenn $P(a_k) = 1$, dann $I(a_k) = 0$.
\end{itemize}
\end{minipage}

\subsection*{Entropie -- mittlerer Info.gehalt}
\begin{minipage}{\columnwidth}
\[
    H = - \sum_{k=1}^{K} \bigg[ P(a_k) \cdot \log_2{P(a_k)} \bigg] \mbox{ [Bit]}
\]
\begin{itemize}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{0pt plus 1pt}
	\item Wenn alle Sym.\ gleich wahrscheinlich $I(a_k) = H_0 = H$
	\item Max.\ bei $P(a_k) = \frac{1}{K}$
    \item Einfachere Berechnung bei $P(a_k) = \frac{i_k}{c}$:
\end{itemize}
\[
    H = \frac{c \cdot \log(c) - \sum\limits_{k=1}^{K} \bigg[ i_k \cdot
        \log(i_k) \bigg]}{c \cdot \log(2)} \mbox{ [Bit]}
\]
\end{minipage}

\subsection*{Redundanz}
\begin{minipage}{\columnwidth}
\[
    R = H_0 - H \mbox{ [Bit]}
\]
\begin{itemize}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{0pt plus 1pt}
	\item relative Red. $\displaystyle R = \frac{H_0 - H}{H}$
\end{itemize}
\end{minipage}

\subsection*{Ideale Codewortlänge}
\[
    n = -\log_2{P(a_k)} \mbox{ [Bit]}
\]

\subsection*{Mittlere Codewortlänge}
\[
    \overline{m} = 
        \sum_{k=1}^{K} \bigg[ P(a_k) 
        \cdot m_k \bigg] \mbox{ [Bit]}
\]

\end{multicols}
